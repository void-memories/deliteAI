# SPDX-FileCopyrightText: (C) 2025 DeliteAI Authors
#
# SPDX-License-Identifier: Apache-2.0

from deliteai import simulator
import numpy as np
import json
import pytest

build_flags = simulator.get_build_flags()

expectedOutput = {
    "listOfStrings": ["a", "b", ":gfdfdsfsdfs"],
    "nestedJson": {"key2":[2,3,"fsd","addValue",1], "key3":"data1", "key4":{"fsd":"fdsd", "newKeyInKey4":"newString", "uio":1.89}, "newKey":[100,900], "bigValue": 12345678911},
    "nestedArray": [{"key1":2, "key2":[1,2,3,"fsd"], "key3":"data1", "key5":[{"x":1}]}],
    "poppedValue": [{"x":1}],
    "poppedValueFromList": [1],
    "char_list": ["H", "e", "l", "l", "o", " ", "t", "h", "e", "r", "e", "!"]
   }

def test_simulator():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/workflow_script.py"
            }
        }
    ]

    # initialize nimblenet    
    assert simulator.initialize('''{"debug": true, "online": false}''', modules)

    input = {"singleString": "singleString", "singleFloat": 10.10, "boolTensor": np.full((3), True, dtype=bool)}

    # Run a method of the workflow script and get inference output
    output = simulator.run_method("main", input, int(86405))

    # Assert the number of outputs
    assert len(output) == 12

    # Assert output generated by the model
    assert output["outputSingleString"] ==  "1234"
    assert np.allclose(output["outputSingleFloat"], 102.01, rtol=1e-6)
    assert np.size(output["emptyTensorOfFloats"])== 0
    assert np.size(output["emptyTensorOfStrings"]) == 0
    assert np.all(np.array(output["listOfStrings"]) == np.array(expectedOutput["listOfStrings"]))
    assert output["countdownZero"] == 0

    # Test tensor operations
    assert np.allclose(output["minTensor"], 0.1, rtol=1e-6)
    assert np.allclose(output["maxTensor"], 4.5, rtol=1e-6)
    assert np.allclose(output["sumTensor"], 10.6, rtol=1e-6)
    assert np.allclose(output["meanTensor"], 2.12, rtol=1e-6)
    assert output["boolTensorStr"] == "[1,1,1]"
    assert np.all(np.array(output["char_list"]) == np.array(expectedOutput["char_list"]))

# This tests that we are able to parse and store nested JSON
def test_nested_json():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/nested_json_script.py"
            }
        }
    ]

    assert simulator.initialize('''{"debug": true, "online": false}''', modules)
    
    nestedJson = {"key1": 1, "key2": [1, 2, 3, "fsd"], "key3": "data1", "key4": {"fsd": "fdsd", "uio": 1.89}, "key5": [{"x": 1}], "bigValue": 12345678910}
    nestedArray = [{"key1": 1, "key2": [1, 2, 3, "fsd"], "key3": "data1", "key4": {"fsd": "fdsd", "uio": 1.89}, "key5": [{"x": 1}]}, "dfs"]
    input = {
        "data":'{"rows": [{"id": 1, "widgets": [{"widgetId": 1, "restaurantId": 2}]}], "restaurants": [{"id": 1, "Name": "XYZ Khaana"}, {"id": 2, "Name": "ABC Foods"}]}',
        "nestedJson": nestedJson, "nestedArray": nestedArray}

    output = simulator.run_method("add_initial_data", input, int(28931))
    
    assert len(output) == 4
    assert output["nestedJson"] == expectedOutput["nestedJson"]
    assert np.all(np.array(output["nestedArray"]) == np.array(expectedOutput["nestedArray"]))
    assert np.all(np.array(output["poppedValue"]) == np.array(expectedOutput["poppedValue"]))
    assert np.all(np.array(output["poppedValueFromList"]) == np.array(expectedOutput["poppedValueFromList"]))


def test_regex():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/regex.py"
            }
        }
    ]

    assert simulator.initialize('''{"debug": true}''', modules)
    output = simulator.run_method("main", {})
    assert len(output.keys()) == 65
    assert np.all(np.asarray(output["split1"]) == np.asarray(['Words', 'words', 'words']))
    assert np.all(np.asarray(output["split2"]) == np.asarray(['Words', ', ', 'words', ', ', 'words', '.']))
    assert np.all(np.asarray(output["split3"]) == np.asarray(['Words', 'words', 'words']))
    assert np.all(np.asarray(output["split4"]) == np.asarray(['0', '3', '9']))
    assert output["match1_group0"] == "Isaac Newton"
    assert output["match1_group1"] == "Isaac Newton"
    assert output["match1_group2"] == "Newton"
    assert np.all(np.asarray(output["match1_group3"]) == np.asarray(["Isaac Newton", "Isaac"]))
    assert output["match2_group0"] == "c3"
    assert output["match5_group"] == "abc"
    assert output["fullmatch1_group0"] == "python"
    assert output["search1_group0"] == "remove_this"
    assert output["search3_group0"] == "a"
    assert np.all(np.asarray(output["match1_groups0"]) == np.asarray(["Isaac Newton", "Isaac", "Newton"]))
    assert np.all(np.asarray(output["match2_groups0"]) == np.asarray(["c3"]))
    assert np.all(np.asarray(output["match3_groups0"]) == np.asarray(["24", "1632"]))
    assert output["match4_groups0_size"] == 2
    assert np.all(np.asarray(output["match4_groups0"]) == np.asarray(["24"]))
    assert output["match4_groups1_size"] == 2
    assert np.all(np.asarray(output["match4_groups1"]) == np.asarray(["24", "1"]))
    assert output["fullmatch1_groups0_size"] == 0
    assert output["search1_groups0_size"] == 0
    assert output["search3_groups0_size"] == 0
    assert output["search3_groups1_size"] == 0
    assert output["match1_start0"] == 0
    assert output["match1_start1"] == 0
    assert output["match1_start2"] == 6
    assert output["match2_start0"] == 4
    assert output["fullmatch1_start"] == 0
    assert output["match4_start0"] == 0
    assert output["match4_start1"] == -1
    assert output["match1_end0"] == 12
    assert output["match1_end1"] == 12
    assert np.all(np.asarray(output["match1_span0"]) == np.asarray([6, 12]))
    assert np.all(np.asarray(output["match2_span0"]) == np.asarray([4, 6]))
    assert np.all(np.asarray(output["match4_span0"]) == np.asarray([0, 2]))
    assert output["match4_end0"] == -1
    assert np.all(np.asarray(output["fullmatch1_span"]) == np.asarray([0, 6]))
    assert output["sub0"] == "Baked Beans & Spam"
    assert output["sub1"] == "Q*ick brown fox"
    assert output["subn0_resultstring"] == "Baked Beans & Spam"
    assert output["subn0_replacements"] == 1
    assert output["subn1_resultstring"] == "Q**ck brown fox"
    assert output["subn1_replacements"] == 2
    assert output["subn2_resultstring"] == "A *** on a *** *** roof"
    assert output["subn2_replacements"] == 3
    assert output["subn3_resultstring"] == "Text"
    assert output["subn3_replacements"] == 4
    assert output["subn4_resultstring"] == "word word!"
    assert output["subn4_replacements"] == 2
    assert output["findall0_size"] == 3
    assert np.all(np.asarray(output["findall0_strings"]) == np.asarray(['foot', 'fell', 'fastest']))
    assert output["findall1_size_products"] == 8
    assert np.all(np.asarray(output["findall1_strings"]) == np.asarray(['width', '20', 'height', '10']))
    assert output["findall2_size"] == 2
    assert np.all(np.asarray(output["findall2_strings"]) == np.asarray(['width', 'height']))
    assert output["findall3_size_products"] == 2
    assert np.all(np.asarray(output["findall3_strings"]) == np.asarray(["width", "set"]))
    assert output["findall4_size_products"] == 2
    assert np.all(np.asarray(output["findall4_strings"]) == np.asarray(["width", "height"]))
    assert output["findall5_size"] == 0
    assert output["findall6_size"] == 2
    assert np.all(np.asarray(output["findall6_strings"]) == np.asarray(["carefully", "quickly"]))
    assert output["finditer0_string"] == "carefullyquickly"
    assert output["finditer1_string"] == ""


@pytest.mark.skipif("GENAI" not in build_flags, reason = "Need GENAI build flag")
def test_json_stream():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/streaming_json.py"
            }
        }
    ]

    assert simulator.initialize("""{"debug": true, "online": false}""", modules)

    simulator.run_method("create_json_stream", {})

    description_out = simulator.run_method("get_description", {})
    print(f"Found description: {description_out['description']}")
    assert description_out["description"] == "this is a description"

    def get_items():
        item = simulator.run_method("get_next_item", {})["item"]
        while item != "":
            print(f"Found item: {item}")
            yield item
            item = simulator.run_method("get_next_item", {})["item"]

    items = list(get_items())
    assert items == ["alpha", "beta", "gamma", "omega"]

# Get the current process

import time
import os
@pytest.mark.skipif(not {"GENAI", "ORT_EXTENSIONS"}.issubset(build_flags), reason = "Need GENAI and ORT_EXTENSIONS build flags")
def test_retriever():
    import psutil
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/retriever.py"
            }
        },
        {
            "name": "GroceryRAG",
            "version": "1.0.0",
            "type": "retriever",
            "arguments": [
                {
                    "name": "embeddingModel",
                    "version": "1.0.0",
                    "type": "model",
                    "location": {
                        "path": "../simulation_assets/embedding_model.onnx"
                    }
                },
                {
                    "name": "embeddingStoreModel",
                    "version": "1.0.0",
                    "type": "model",
                    "location": {
                        "path": "../simulation_assets/embedding_store_model.onnx"
                    }
                },
                {
                    "name": "groceryItems",
                    "version": "1.0.0",
                    "type": "document",
                    "location": {
                        "path": "../simulation_assets/grocery.json"
                    }
                }
            ]
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)
    process = psutil.Process(os.getpid())

    def get_cpu_usage_of_process_in_time(waitTime):
        cpu_usage = process.cpu_percent(interval=waitTime)
        print("Current cpu usage:", cpu_usage)
        return cpu_usage

    assert get_cpu_usage_of_process_in_time(1) <= 2

    simulator.run_method("run_llm",{})

    assert get_cpu_usage_of_process_in_time(1) > 5

    description_out = simulator.run_method("get_description", {})
    print(f"""Found description: {description_out["description"]}""")

    assert description_out["description"] == "this is a description"

    def get_items():
        item = simulator.run_method("get_next_item", {})["item"]
        while item != "":
            print(f"Found item: {item['ProductName']} {item}")
            yield item
            item = simulator.run_method("get_next_item", {})["item"]
    


    items = list(get_items())
    def contains_case_insensitive(main_str, sub_str):
        return sub_str.lower() in main_str.lower()
    assert contains_case_insensitive(items[0]['ProductName'],"milk")
    assert contains_case_insensitive(items[1]['ProductName'],"paneer")
    assert contains_case_insensitive(items[2]['ProductName'],"noodles")
    assert contains_case_insensitive(items[3]['ProductName'],"egg")
    # thread should be idle as processing should be finished by now
    assert get_cpu_usage_of_process_in_time(2) <= 2

def test_tts_tokenizer():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/tts_tokenizer.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)
    with open("../simulation_assets/vocab.json", 'r') as f:
        data = json.load(f)

    output = simulator.run_method("init", {"vocab": data})

    english_tokens = simulator.run_method("tokenize", {"text": "Hello, how are you?", "language": "en"})
    hindi_tokens = simulator.run_method("tokenize", {"text": "à¤µà¥ˆà¤œà¥à¤žà¤¾à¤¨à¤¿à¤• à¤…à¤¨à¥à¤¸à¤‚à¤§à¤¾à¤¨ à¤•à¥‡ à¤ªà¤°à¤¿à¤£à¤¾à¤®à¤¸à¥à¤µà¤°à¥‚à¤ª à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤¹à¥‹à¤¨à¥‡ à¤µà¤¾à¤²à¥€ à¤¨à¤µà¥€à¤¨à¤¤à¤® à¤¤à¤•à¤¨à¥€à¤•à¥‹à¤‚ à¤•à¤¾ à¤¸à¤®à¥à¤šà¤¿à¤¤ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤•à¥‡ à¤¹à¤® à¤¨ à¤•à¥‡à¤µà¤² à¤…à¤ªà¤¨à¥‡ à¤ªà¤°à¥à¤¯à¤¾à¤µà¤°à¤£à¥€à¤¯ à¤¸à¤‚à¤¸à¤¾à¤§à¤¨à¥‹à¤‚ à¤•à¥€ à¤°à¤•à¥à¤·à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤¬à¤²à¥à¤•à¤¿ à¤¸à¤¤à¤¤ à¤µà¤¿à¤•à¤¾à¤¸ à¤•à¥‡ à¤²à¤•à¥à¤·à¥à¤¯à¥‹à¤‚ à¤•à¥‹ à¤­à¥€ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤° à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤", "language": "hi"})

    assert np.all(np.array(english_tokens["tokens"]) == np.array([0, 107, 104, 111, 111, 114, 205, 0, 107, 114, 122, 0, 100, 117, 104, 0, 124, 114, 120, 211, 0]))
    assert np.all(np.array(hindi_tokens["tokens"]) == np.array([0, 172, 186, 150, 190, 152, 178, 162, 179, 143, 0, 129, 162, 181, 175, 127, 161, 178, 162, 0, 143, 185, 0, 163, 169, 179, 157, 178, 167, 175, 190, 172, 169, 182, 163, 0, 172, 179, 143, 175, 179, 158, 0, 176, 188, 162, 185, 0, 172, 178, 170, 180, 0, 162, 172, 180, 162, 158, 167, 0, 158, 143, 162, 180, 143, 188, 127, 0, 143, 178, 0, 175, 167, 181, 148, 179, 158, 0, 133, 163, 168, 188, 145, 0, 143, 169, 143, 185, 0, 176, 167, 0, 162, 0, 143, 185, 172, 170, 0, 129, 163, 162, 185, 0, 163, 169, 190, 168, 178, 172, 169, 157, 180, 168, 0, 175, 127, 175, 178, 161, 162, 188, 127, 0, 143, 180, 0, 169, 143, 190, 174, 178, 0, 143, 169, 0, 175, 143, 158, 185, 0, 176, 186, 127, 205, 0, 165, 170, 190, 143, 179, 0, 175, 158, 158, 0, 172, 179, 143, 178, 175, 0, 143, 185, 0, 170, 143, 190, 174, 190, 168, 188, 127, 0, 143, 188, 0, 166, 180, 0, 163, 190, 169, 178, 163, 190, 158, 0, 143, 169, 0, 175, 143, 158, 185, 0, 176, 186, 127, 0]))

def test_class_support():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/class_support.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)
    
    def assert_callback(output):
        print("asserting callback", output)
        assert output["workflow_output"] == output["actual_output"]
        return {}

    def test_script(val):
        output = simulator.run_method("test_workflow", {"input": val,"assertion_callback":assert_callback})

    test_script(1)
    test_script(2)
    test_script(3)
    

def test_invalid_dataType_model():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/invalid_model_workflow_script.py"
            }
        },
        {
            "name": "simple_fp32_to_fp16_add",
            "version": "1.0.0",
            "type": "model",
            "location": {
                "path": "../simulation_assets/simple_fp32_to_fp16_add.onnx"
            }
        }
    ]
    
    assert simulator.initialize('''{"online": false}''', modules)

    output = simulator.run_method("invalid_model_function", {})
    assert len(output.keys()) == 0

@pytest.mark.skipif("MINIMAL_BUILD" in build_flags, reason = "MultiThreading not supported in minimal build")
def test_multi_threading():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/parallel.py"
            }
        }
    ]
    
    import psutil
    process = psutil.Process(os.getpid())
    taskThreadIndex = process.num_threads()

    # While loading the script, number of threads should increase
    assert simulator.initialize('''{"online": false}''', modules)
    
    if {"GENAI"}.issubset(build_flags):
        assert process.num_threads() == taskThreadIndex + 6
    else:
         assert process.num_threads() == taskThreadIndex + 5

    try:
        # throwing exception in parallel part
        simulator.run_method("throw_exception_in_parallel",{})
        raise Exception("Method should return exception")
    except RuntimeError as err:
        message = str(err)
        assert "trying to set" in message

    def test(n):
        output = simulator.run_method("test_parallel", {"n": n})
        assert output["incorrectTotal"] < n 
        assert output["correctTotal"] == n
        indexTensor = np.array([x for x in range(n)], np.int64)
        squareTensor = np.array([x**2 for x in range(n)], np.int64)
        assert np.all(output["indexTensor"] == indexTensor)
        assert np.all(output["squareTensor"] == squareTensor)
        assert np.all(output["globalTensor"][:10] == indexTensor[:10])
        ## this assumes that the last 100 indices are not set
        assert np.all(output["globalTensor"][-10:] == np.zeros([10],np.int64))
        assert len(output["map"]) == n
        for k in range(n):
            assert str(k) in output["map"]
        # sleeping for 50ms between each call so that spinning threads sleep

        time.sleep(0.050)

    test(100)
    test(1000)
    test(10000)


@pytest.mark.skipif("MINIMAL_BUILD" in build_flags, reason = "MultiThreading not supported in minimal build")
def test_multi_threading_with_limited_threads():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/parallel_limited_threads.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)
 
    def test(n):
        # Test with limited number of threads
        output = simulator.run_method("test_parallel_inside_parallel", {"n": n})
        print(output)
        assert len(output["map"]) == n
        for k in range(n):
            assert str(k) in output["map"]
        time.sleep(0.050)
        

    test(10)


def test_try_catch():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/try_catch.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)

    output = simulator.run_method("try_catch_test",{})

def test_string_slicing():
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/string_slicing_test.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)
    ## Test ASCII string slicing
    ascii_output = simulator.run_method("test_ascii_string_slicing", {"s": "Hello, World!"})
    assert ascii_output["s[0:5:1]"] == "Hello"
    assert ascii_output["s[7:12:1]"] == "World"
    assert ascii_output["s[0::2]"] == "Hlo ol!"
    assert ascii_output["s[::-1]"] == "!dlroW ,olleH"
    assert ascii_output["s[5:7:1]"] == ", "
    assert ascii_output["s[-6:-1:1]"] == "World"
    # Test Unicode string slicing
    unicode_output = simulator.run_method("test_unicode_string_slicing", {"s": "Hello, ä¸–ç•Œ! ðŸŒ"})
    assert unicode_output["s[0:5:1]"] == "Hello"
    assert unicode_output["s[7:9:1]"] == "ä¸–ç•Œ"
    assert unicode_output["s[-3::1]"] == "! ðŸŒ"
    assert unicode_output["s[0::2]"] == "Hlo ç•Œ "
    assert unicode_output["s[::-1]"] == "ðŸŒ !ç•Œä¸– ,olleH"

    # Test edge cases
    edge_output = simulator.run_method("test_edge_cases", {"s": "Python"})
    assert edge_output["s[0:0:1]"] == ""
    assert edge_output["s[100:200:1]"] == ""
    assert edge_output["s[-100:-50:1]"] == ""
    assert edge_output["s[2:2:1]"] == ""
    assert edge_output["s[::1]"] == "Python"

    # Test mixed Unicode slicing
    mixed_output = simulator.run_method("test_mixed_unicode_slicing", {"s": "Hello ä¸–ç•Œ! ðŸŒ Python"})
    assert mixed_output["s[6:8:1]"] == "ä¸–ç•Œ"
    assert mixed_output["s[9:11:1]"] == " ðŸŒ"
    assert mixed_output["s[11:13:1]"] == " P"
    assert mixed_output["s[0::3]"] == "Hlä¸– Ph"
    assert mixed_output["s[::-2]"] == "nhy  ç•Œ le"



def test_list_operations():
    """Test all list operations implemented in the C++ runtime."""
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/list_ops_test.py"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)

    # Test basic list creation
    basic_lists = simulator.run_method("test_basic_lists", {})
    assert len(basic_lists) == 4
    assert len(basic_lists["empty_list"]) == 0
    assert np.all(np.array(basic_lists["numbers"]) == np.array([1, 2, 3, 4, 5]))
    assert basic_lists["mixed"][0] == 1
    assert basic_lists["mixed"][1] == "hello"
    assert np.isclose(basic_lists["mixed"][2], 3.14)
    assert basic_lists["mixed"][3] == True
    assert basic_lists["nested"][0] == 1
    assert np.all(np.array(basic_lists["nested"][1]) == np.array([2, 3]))

    # Test list concatenation
    concat_results = simulator.run_method("test_concatenation", {})
    assert len(concat_results) == 4
    assert np.all(np.array(concat_results["concatenated"]) == np.array([1, 2, 3, 4, 5, 6]))
    assert np.all(np.array(concat_results["empty_concat"]) == np.array([1, 2, 3]))
    assert np.all(np.array(concat_results["list_empty_concat"]) == np.array([1, 2, 3]))
    assert concat_results["mixed_concat"][0] == 1
    assert concat_results["mixed_concat"][3] == "hello"

    # Test list repetition
    repeat_results = simulator.run_method("test_repetition", {})
    assert len(repeat_results) == 5
    assert np.all(np.array(repeat_results["repeated"]) == np.array([1, 2, 3, 1, 2, 3, 1, 2, 3]))
    assert len(repeat_results["zero_repeat"]) == 0
    assert np.all(np.array(repeat_results["one_repeat"]) == np.array([1, 2, 3]))
    assert len(repeat_results["empty_repeat"]) == 0
    assert np.all(np.array(repeat_results["int_mult_list"]) == np.array([1, 2, 3, 1, 2, 3, 1, 2, 3]))

    # Test element membership
    membership_results = simulator.run_method("test_membership", {})
    assert len(membership_results) == 5
    assert membership_results["contains_1"] == True
    assert membership_results["contains_4"] == False
    assert membership_results["contains_hello"] == True
    assert membership_results["contains_float"] == True
    assert membership_results["contains_nested"] == True

    # Test list slicing
    slice_results = simulator.run_method("test_slicing", {})
    assert len(slice_results) == 9
    assert np.all(np.array(slice_results["slice_2_5"]) == np.array([2, 3, 4]))
    assert np.all(np.array(slice_results["slice_begin"]) == np.array([0, 1, 2]))
    assert np.all(np.array(slice_results["slice_end"]) == np.array([7, 8, 9]))
    assert np.all(np.array(slice_results["slice_all"]) == np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))
    assert np.all(np.array(slice_results["slice_neg_end"]) == np.array([7, 8, 9]))
    assert np.all(np.array(slice_results["slice_neg_begin"]) == np.array([0, 1, 2, 3, 4, 5, 6, 7]))
    assert np.all(np.array(slice_results["slice_step"]) == np.array([0, 2, 4, 6, 8]))
    assert np.all(np.array(slice_results["slice_begin_end_step"]) == np.array([1, 4, 7]))
    assert np.all(np.array(slice_results["slice_reverse"]) == np.array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]))

    # Test list comprehension
    simulator.run_method("test_comprehension", {})

    # Test multiple conditions in list comprehensions
    simulator.run_method("test_multiple_conditions", {})
    
    # Test modulo operations - assertions are in the test functions
    simulator.run_method("test_mod_operations", {})
    
    # Test concatenation edge cases - assertions are in the test functions
    simulator.run_method("test_concatenation_edge_cases", {})

    print("All list operation tests passed!")


def test_python_modules():
    """Test support for DelitePy modules implemented in the C++ runtime."""
    modules = [
        {
            "name": "workflow_script",
            "version": "1.0.0",
            "type": "script",
            "location": {
                "path": "../simulation_assets/valid_script_modules.zip"
            }
        }
    ]

    assert simulator.initialize('''{"online": false}''', modules)

    results = simulator.run_method("run", {})
    assert len(results) == 2
    assert results["main_A"] == 3
    assert results["module1_A"] == 4

    try:
        simulator.run_method("module1_run", {})
        raise Exception("Method call for function in module should fail")
    except RuntimeError as err:
        assert "module1_run not defined in task" in repr(err)

    print("All python modules test passed!")
    
if __name__ == "__main__":
    test_simulator()
    test_python_modules()
